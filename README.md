# üì° Telecom Churn AI

![Python](https://img.shields.io/badge/Python-3.x-blue)
![Scikit-Learn](https://img.shields.io/badge/Library-Scikit--Learn-orange)
![Tests](https://img.shields.io/badge/Tests-Passing-green)
![Status](https://img.shields.io/badge/Status-POC_Completed-brightgreen)

## üìÑ Contexte du Projet

Ce projet r√©pond √† un besoin critique d'une entreprise de t√©l√©communications : **pr√©dire le d√©sabonnement (Churn) de ses clients**.
L'objectif est de d√©velopper un pipeline de Machine Learning supervis√© capable d'identifier les clients √† risque afin d'orienter les strat√©gies de fid√©lisation de l'√©quipe marketing.

## üéØ Objectifs R√©alis√©s
- **Exploration (EDA)** : Analyse des corr√©lations et distribution des donn√©es via Jupyter Notebook.
- **Pipeline Automatis√©** : Script Python g√©rant le chargement, le nettoyage, l'encodage et l'entra√Ænement.
- **Qualit√© Code** : Mise en place de tests unitaires (`pytest`) pour valider la robustesse du code.
- **Mod√©lisation** : Comparaison des performances entre *Logistic Regression* et *Random Forest*.

---

## üìÇ Structure du Projet

```bash
‚îú‚îÄ‚îÄ data/
‚îÇ   ‚îî‚îÄ‚îÄ raw/
‚îÇ       ‚îî‚îÄ‚îÄ ChurnDataFile.csv    # Donn√©es sources (Ne jamais modifier directement)
‚îú‚îÄ‚îÄ notebooks/
‚îÇ   ‚îî‚îÄ‚îÄ NoteBookJupyter.ipynb                # Notebook Jupyter : Exploration (EDA) et brouillon
‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îú‚îÄ‚îÄ pipeline.py              # Pipeline complet : Pr√©paration, Entra√Ænement, √âvaluation
‚îÇ   ‚îî‚îÄ‚îÄ test_pipeline.py         # Tests unitaires (pytest) pour valider le pipeline
‚îú‚îÄ‚îÄ ChurnEnvr/                   # Environnement virtuel Python (contient les librairies)
‚îú‚îÄ‚îÄ requirements.txt             # Liste des d√©pendances (pandas, sklearn, pytest...)
‚îî‚îÄ‚îÄ README.md                    # Documentation du projet
```

-----

## üöÄ Installation et Lancement

### 1\. Installation de l'environnement

```bash
# Cr√©ation de l'environnement virtuel
python -m venv ChurnEnvr

# Activation (Windows)
.\ChurnEnvr\Scripts\activate

# Installation des d√©pendances
pip install -r requirements.txt
```

### 2\. Ex√©cution du Pipeline

Pour lancer le chargement des donn√©es, l'entra√Ænement et voir les r√©sultats :

```bash
python src/pipeline.py
```

### 3\. Ex√©cution des Tests

Pour v√©rifier que tout fonctionne (Data Quality & Logic) :

```bash
pytest src/test_pipeline.py
```

*R√©sultat attendu : `2 passed`*

-----

## üìä R√©sultats et Performance

Deux mod√®les ont √©t√© entra√Æn√©s et compar√©s sur un jeu de test de **1409 clients** (20% du dataset).

| M√©trique | R√©gression Logistique (Retenu) | Random Forest |
|----------|--------------------------------|---------------|
| **Accuracy** | **79.8%** | 79.1% |
| **Recall (Rappel)** | **54.3%** | 50.0% |
| **F1-Score** | **0.59** | 0.56 |
| **ROC AUC** | **0.84** | 0.82 |

### üß† Analyse Technique

Le mod√®le **R√©gression Logistique** a √©t√© s√©lectionn√© pour la mise en production.

1.  **Meilleure d√©tection (Recall) :** Il identifie mieux les clients qui vont r√©ellement partir (54.3%) compar√© au Random Forest.
2.  **Robustesse (ROC AUC) :** Avec un score de 0.84, il offre une excellente capacit√© de discrimination entre les clients fid√®les et les d√©sabonn√©s.
3.  **Simplicit√© :** Mod√®le plus l√©ger et plus rapide √† interpr√©ter.

-----

## ‚öôÔ∏è D√©tails du Pipeline (Feature Engineering)

Le script `pipeline.py` effectue automatiquement les transformations suivantes :

1.  **Nettoyage** : Gestion des valeurs vides dans `TotalCharges`.
2.  **Encodage** : Transformation des variables cat√©gorielles (ex: 'Yes'/'No' -\> 1/0) via `LabelEncoder`.
3.  **Normalisation** : Mise √† l'√©chelle des variables num√©riques via `MinMaxScaler` pour optimiser la convergence des algorithmes.
4.  **Split Stratifi√©** : Division Train/Test respectant la proportion de Churn initial.


